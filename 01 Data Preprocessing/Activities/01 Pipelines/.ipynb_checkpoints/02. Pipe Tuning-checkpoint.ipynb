{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:30px 0px;\">\n",
    "    <h1 align=\"center\" style=\"padding:50px\">Hyperparameter Tuning With Pipelines</h1>\n",
    "    <p align=\"center\" style=\"font-size:small;\">Seth Pruitt<br>spruitt@norstal.com<br>www.github.com/faradical</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=100)\n",
    "\n",
    "# Split the data into traing and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Pipeline Step Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - Grid Search Inside a Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'copy_X': [True, False],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation\n",
    "grid = GridSearchCV(LinearRegression(), param_grid, cv=5)\n",
    "\n",
    "# Defining our pipeline and steps\n",
    "p1 = Pipeline([\n",
    "    (\"Scaler\", StandardScaler()),\n",
    "    (\"Linear Regression\", grid)\n",
    "])\n",
    "\n",
    "# Fit and score the pipeline\n",
    "p1.fit(X_train, y_train)\n",
    "p1.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - Pipe Inside a Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our pipeline and steps\n",
    "p2 = Pipeline([\n",
    "    (\"Scaler\", StandardScaler()),\n",
    "    (\"Linear Regression\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Define a dictionary of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'Linear Regression__copy_X': [True, False],\n",
    "    'Linear Regression__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation\n",
    "grid = GridSearchCV(p2, param_grid, cv=5)\n",
    "\n",
    "# Fit and score the pipeline\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating More Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "\n",
    "def y_f(x):\n",
    "    return (0.5 * (x**2)) + (2 * x) + 6\n",
    "\n",
    "X = np.arange(222)\n",
    "y = [y_f(x)+rn.randint(-2000,2000) for x in X]\n",
    "\n",
    "# Plotting the dummy data\n",
    "plt.figure(facecolor='gray', figsize=(15,10)).set_alpha(0.0)\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"gray\")\n",
    "ax.set_alpha(0.0)\n",
    "\n",
    "plt.scatter(X, y, c='red', marker=\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into traing and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a New Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PolynomialFeatures to help fit the linear model to the curve\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Creating a reshape function\n",
    "def reshape(X):\n",
    "    return X.reshape(-1, 1)\n",
    "\n",
    "# Defining a new pipeline\n",
    "steps = [\n",
    "    (\"Reshape\", FunctionTransformer(reshape)),\n",
    "    (\"Scaler\", StandardScaler()),\n",
    "    (\"PolynomialFeatures\", PolynomialFeatures()),\n",
    "    (\"Linear Regression\", LinearRegression())\n",
    "]\n",
    "p3 = Pipeline(steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing a Grid Search Over the New Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of hyperparameters for both the model and pipeline steps.\n",
    "param_grid = {\n",
    "    'Scaler__with_mean': [True, False],\n",
    "    'Scaler__with_std': [True, False],\n",
    "    'PolynomialFeatures__degree': np.arange(1,4),\n",
    "    'PolynomialFeatures__interaction_only': [True, False],\n",
    "    'PolynomialFeatures__include_bias': [True, False],\n",
    "    'PolynomialFeatures__order': ['C', 'F'],\n",
    "    'Linear Regression__copy_X': [True, False],\n",
    "    'Linear Regression__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation\n",
    "grid = GridSearchCV(p3, param_grid, cv=5)\n",
    "\n",
    "# Fit and score the pipeline\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
